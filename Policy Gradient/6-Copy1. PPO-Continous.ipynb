{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from src.PPO.PPO import PPO, PPOContinuous\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "env_name = \"BipedalWalker-v2\"\n",
    "env = gym.make(env_name)\n",
    "\n",
    "env.seed(10)\n",
    "\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size =env.action_space.shape[0]\n",
    "\n",
    "print(state_size)\n",
    "print(action_size)\n",
    "\n",
    "# PPO Settings\n",
    "update_every = 4000\n",
    "num_learn = 80\n",
    "win_condition = 300\n",
    "\n",
    "# Agent settings\n",
    "hidden_size=64\n",
    "epsilon=0.2\n",
    "entropy_beta=0.01\n",
    "gamma=0.99\n",
    "lr=0.0003\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PPOContinuous(state_size, action_size, hidden_size=hidden_size, epsilon=epsilon, entropy_beta=entropy_beta, gamma=gamma, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7\tAverage Score: -57.31\tScore: -101.06"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darylrodrigo/Desktop/rl_lib/Policy Gradient/src/PPO/PPO.py:125: UserWarning: Using a target size (torch.Size([8000])) that is different to the input size (torch.Size([8000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = -torch.min(surrogate_1, surrogate_2) + 0.5*F.mse_loss(values, discounted_returns) - self.entropy_beta*entropy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Time: 173.14997100830078\n",
      "Learning Time: 37.81682467460632\tScore: -51.081\n",
      "Learning Time: 37.67802619934082\tScore: -40.688\n",
      "Learning Time: 37.010924100875854Score: -102.19\n",
      "Learning Time: 37.54847598075867\tScore: -37.142\n",
      "Learning Time: 37.223000049591064Score: -122.36\n",
      "Learning Time: 37.405943870544434Score: -31.210\n",
      "Learning Time: 37.213414907455444Score: -32.988\n",
      "Learning Time: 37.33086395263672\tScore: -116.63\n",
      "Learning Time: 37.73776102066046\tScore: -50.057\n",
      "Learning Time: 37.38165807723999\tScore: -32.945\n",
      "Episode 100\tAverage Score: -69.29\tScore: -58.84\n",
      "Learning Time: 38.490575075149536\tScore: -32.424\n",
      "Learning Time: 86.510607957839976\tScore: -34.394\n",
      "Learning Time: 88.148627996444701\tScore: -42.167\n",
      "Learning Time: 44.283063650131226\tScore: -104.17\n",
      "Learning Time: 48.121879100799564\tScore: -45.157\n",
      "Episode 147\tAverage Score: -72.44\tScore: -45.921"
     ]
    }
   ],
   "source": [
    "\n",
    "scores_deque = deque(maxlen=100)\n",
    "scores = []\n",
    "average_scores = []\n",
    "max_score = -np.Inf\n",
    "\n",
    "def train(n_episodes=4000, max_t=700):\n",
    "#   agent = PPO(state_size, action_size, hidden_size=hidden_size, epsilon=epsilon, entropy_beta=entropy_beta, gamma=gamma, lr=lr)\n",
    "  steps = 0\n",
    "\n",
    "  for episode in range(1, n_episodes+1):\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    \n",
    "    for t in range(max_t):\n",
    "      steps += 1\n",
    "\n",
    "      actions_tensor, log_prob = agent.act(torch.FloatTensor(state).to(device))\n",
    "      actions = actions_tensor.cpu().data.numpy().flatten()\n",
    "      next_state, reward, done, _ = env.step(actions_tensor.cpu().numpy())\n",
    "\n",
    "      agent.mem.add(torch.FloatTensor(state), actions, reward, log_prob, done)\n",
    "\n",
    "      # Update \n",
    "      state = next_state\n",
    "      score += reward\n",
    "\n",
    "      if steps >= update_every:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        agent.learn(num_learn)\n",
    "        agent.mem.clear()\n",
    "        steps = 0\n",
    "\n",
    "        print(\"\\rLearning Time: {}\".format(time.time()-start_time))\n",
    "\n",
    "      if done:\n",
    "        break\n",
    "    \n",
    "    # Book Keeping\n",
    "    scores_deque.append(score)\n",
    "    scores.append(score)\n",
    "    average_scores.append(np.mean(scores_deque))\n",
    "      \n",
    "\n",
    "    print(\"\\rEpisode {}\tAverage Score: {:.2f}\tScore: {:.2f}\".format(episode, np.mean(scores_deque), score), end=\"\")\n",
    "\n",
    "    if episode % 100 == 0:\n",
    "      print(\"\\rEpisode {}\tAverage Score: {:.2f}\".format(episode, np.mean(scores_deque)))   \n",
    "      torch.save(agent.model.state_dict(), \"walker_ppo_model_{}.pth\".format(episode))\n",
    "      torch.save(agent.model_old.state_dict(), \"walker_ppo_model_old_{}.pth\".format(episode))\n",
    "    \n",
    "    if np.mean(scores_deque) > win_condition:\n",
    "      print(\"\\rEnvironment Solved in {} episodes!\".format(episode))\n",
    "      break\n",
    "\n",
    "\n",
    "  return scores, average_scores\n",
    "\n",
    "scores, average_scores = train()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.save(agent.model.state_dict(), \"walker_ppo_model.pth\")\n",
    "torch.save(agent.model_old.state_dict(), \"walker_ppo_model_old.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)\n",
    "plt.plot(average_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(0):\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    input()\n",
    "\n",
    "    for t in range(30000):\n",
    "        actions_tensor, log_prob = agent.act(torch.FloatTensor(state))\n",
    "        actions = actions_tensor.cpu().data.numpy().flatten()\n",
    "        next_state, reward, done, _ = env.step(actions_tensor)\n",
    "\n",
    "        \n",
    "        score += reward\n",
    "        \n",
    "        env.render()\n",
    "        \n",
    "        if done:\n",
    "            break;\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "    print(score)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning Time: 40.54673504829407\n",
    "Learning Time: 41.96533799171448\tScore: -50.15\n",
    "Learning Time: 40.52155685424805\tScore: -32.68\n",
    "Learning Time: 39.72044110298157\tScore: -35.29\n",
    "Learning Time: 39.37555003166199\tScore: -34.61\n",
    "Learning Time: 39.28577804565433\tScore: -32.512\n",
    "Learning Time: 39.48905801773071\tScore: -41.78\n",
    "Learning Time: 37.73234200477635\tScore: -53.93\n",
    "Learning Time: 37.45758390426636\tScore: -100.15\n",
    "Learning Time: 37.49617815017761\tScore: -35.22\n",
    "Learning Time: 37.77951502799988\tScore: -34.89\n",
    "Learning Time: 37.48916983604431\tScore: -40.78\n",
    "Learning Time: 37.69424891471863\tScore: -35.52\n",
    "Learning Time: 38.07879686355591\tScore: -102.34\n",
    "Episode 100\tAverage Score: -51.22\tScore: -102.81\n",
    "Learning Time: 37.465858221054083\tScore: -100.50\n",
    "Learning Time: 37.470584869384766\tScore: -100.71\n",
    "Learning Time: 37.296790838241581\tScore: -100.70\n",
    "Learning Time: 58.151881933212287\tScore: -102.24\n",
    "Learning Time: 58.688025951385556\tScore: -41.10\n",
    "Learning Time: 61.566057920455933\tScore: -40.929\n",
    "Learning Time: 50.702331066131590\tScore: -101.60\n",
    "Learning Time: 37.473351955413823\tScore: -43.493\n",
    "Episode 200\tAverage Score: -90.31\tScore: -116.74\n",
    "Learning Time: 37.415262937545776\tScore: -102.61\n",
    "Learning Time: 37.678329229354865\tScore: -106.37\n",
    "Learning Time: 36.9206130504608158\tScore: -101.46\n",
    "Learning Time: 36.7081129550933847\tScore: -101.11\n",
    "Episode 300\tAverage Score: -107.58\tScore: -127.65\n",
    "Learning Time: 36.6818459033966061\tScore: -100.49\n",
    "Learning Time: 36.6596653461456322\tScore: -100.17\n",
    "Learning Time: 36.7583160400390674\tScore: -110.83\n",
    "Learning Time: 36.5183839797973635\tScore: -102.69\n",
    "Learning Time: 36.7789819240570147\tScore: -135.37\n",
    "Episode 400\tAverage Score: -107.91\tScore: -99.783\n",
    "Learning Time: 36.9678218364715682\tScore: -66.369\n",
    "Learning Time: 36.5511198043823242\tScore: -121.94\n",
    "Learning Time: 36.6014571189880467\tScore: -103.22\n",
    "Learning Time: 36.9071187973022464\tScore: -100.30\n",
    "Episode 500\tAverage Score: -108.07\tScore: -106.43\n",
    "Learning Time: 43.9723660945892351\tScore: -117.30\n",
    "Learning Time: 40.5132012367248553\tScore: -125.65\n",
    "Learning Time: 42.3397359848022463\tScore: -104.43\n",
    "Learning Time: 43.1013031005859400\tScore: -100.21\n",
    "Learning Time: 49.8743638992309674\tScore: -109.04\n",
    "Episode 600\tAverage Score: -105.86\tScore: -113.37\n",
    "Learning Time: 47.3777740001678587\tScore: -100.14\n",
    "Learning Time: 50.6292541027069152\tScore: -100.24\n",
    "Learning Time: 45.6308989524841393\tScore: -100.59\n",
    "Learning Time: 41.7782220840454160\tScore: -102.72\n",
    "Learning Time: 39.8999428749084507\tScore: -103.85\n",
    "Episode 700\tAverage Score: -97.33\tScore: -126.92\n",
    "Learning Time: 40.285196065902712\tScore: -101.06\n",
    "Learning Time: 40.153511047363284\tScore: -131.01\n",
    "Learning Time: 41.997211933135986\tScore: -43.998\n",
    "Learning Time: 40.493303060531616\tScore: -46.248\n",
    "Learning Time: 40.311293840408325\tScore: -52.013\n",
    "Learning Time: 40.479155063629151\tScore: -103.25\n",
    "Learning Time: 40.168627023696996\tScore: -104.30\n",
    "Episode 800\tAverage Score: -96.21\tScore: -47.271\n",
    "Learning Time: 40.477483987808234\tScore: -43.73\n",
    "Learning Time: 40.945652008056645\tScore: -52.607\n",
    "Learning Time: 40.066672801971436\tScore: -41.097\n",
    "Learning Time: 38.698684930801396\tScore: -43.758\n",
    "Learning Time: 39.487704753875735\tScore: -49.63\n",
    "Learning Time: 40.026069164276129\tScore: -103.65\n",
    "Learning Time: 39.121330261230478\tScore: -103.18\n",
    "Learning Time: 39.961763143539431\tScore: -121.05\n",
    "Learning Time: 39.563637018203735\tScore: -47.603\n",
    "Learning Time: 40.388886213302616\tScore: -43.777\n",
    "Episode 900\tAverage Score: -85.55\tScore: -45.70\n",
    "Learning Time: 38.532398939132698\tScore: -40.347\n",
    "Learning Time: 37.279074907302856\tScore: -59.321\n",
    "Learning Time: 37.005691289901738\tScore: -49.743\n",
    "Learning Time: 37.948124885559089\tScore: -36.23\n",
    "Learning Time: 39.795126199722290\tScore: -45.60\n",
    "Learning Time: 40.372703075408936\tScore: -33.18\n",
    "Learning Time: 37.719485044479377\tScore: -37.318\n",
    "Learning Time: 40.048268079757694\tScore: -35.95\n",
    "Learning Time: 38.895526170730599\tScore: -32.90\n",
    "Learning Time: 39.228843927383429\tScore: -36.23\n",
    "Learning Time: 40.090528011322029\tScore: -35.04\n",
    "Learning Time: 40.450932025909424\tScore: -36.85\n",
    "Learning Time: 40.717709064483648\tScore: -33.64\n",
    "Learning Time: 40.037404060363772\tScore: -37.16\n",
    "Learning Time: 40.125184059143066\tScore: -33.95\n",
    "Learning Time: 39.859297037124634\tScore: -30.23\n",
    "Episode 1000\tAverage Score: -42.72\tScore: -38.51\n",
    "Learning Time: 39.3126468658447334\tScore: -112.81\n",
    "Learning Time: 43.1875679492950440\tScore: -43.952\n",
    "Learning Time: 43.7944908142089846\tScore: -42.03\n",
    "Learning Time: 45.3535907268524204\tScore: -37.260\n",
    "Learning Time: 43.1859469413757391\tScore: -32.99\n",
    "Learning Time: 40.1571178436279300\tScore: -35.44\n",
    "Learning Time: 40.4242286682128906\tScore: -34.655\n",
    "Learning Time: 40.7080061435699464\tScore: -37.61\n",
    "Learning Time: 40.3114900588989266\tScore: -35.05\n",
    "Learning Time: 40.4351949691772465\tScore: -44.15\n",
    "Learning Time: 40.4176392555236854\tScore: -35.94\n",
    "Learning Time: 40.2799270153045653\tScore: -37.88\n",
    "Learning Time: 40.6512277126312269\tScore: -36.84\n",
    "Learning Time: 38.4469420909881631\tScore: -28.376\n",
    "Learning Time: 38.8761558532714842\tScore: -29.18\n",
    "Learning Time: 38.2418050765991280\tScore: -24.89\n",
    "Learning Time: 38.1750431060791.78\tScore: -33.66\n",
    "Episode 1100\tAverage Score: -39.76\tScore: -36.17\n",
    "Learning Time: 38.1902880668640143\tScore: -41.48\n",
    "Learning Time: 38.6219561100006188\tScore: -32.64\n",
    "Learning Time: 38.3393511772155761\tScore: -37.25\n",
    "Learning Time: 38.5834698677063.37\tScore: -28.70\n",
    "Learning Time: 38.3533101081848146\tScore: -112.73\n",
    "Learning Time: 38.0739839076995852\tScore: -129.32\n",
    "Learning Time: 38.1755278110504156\tScore: -28.88\n",
    "Learning Time: 38.4516592025756845\tScore: -29.71\n",
    "Learning Time: 39.0045912265777634\tScore: -30.619\n",
    "Learning Time: 55.2141561508178761\tScore: -30.441\n",
    "Learning Time: 45.9561002254486145\tScore: -29.213\n",
    "Learning Time: 48.2231998443603539\tScore: -30.91\n",
    "Learning Time: 41.7471559047699.00\tScore: -32.92\n",
    "Learning Time: 41.6580412387847968\tScore: -23.79\n",
    "Learning Time: 42.2896039485931422\tScore: -16.27\n",
    "Episode 1200\tAverage Score: -41.73\tScore: -32.78\n",
    "Learning Time: 54.279879093170166\n",
    "Learning Time: 42.2410078048706057\tScore: -24.96\n",
    "Learning Time: 42.0439379215240567\tScore: -26.68\n",
    "Learning Time: 42.6554787158966067\tScore: -16.73\n",
    "Learning Time: 45.6630799770355282\tScore: -27.09\n",
    "Learning Time: 41.9235117435455361\tScore: -17.77\n",
    "Learning Time: 42.0443558692932146\tScore: -20.91\n",
    "Learning Time: 42.2250380516052258\tScore: -23.95\n",
    "Learning Time: 47.1960237026214685\tScore: -23.75\n",
    "Learning Time: 43.4167301654815746\tScore: -34.70\n",
    "Learning Time: 41.8681437969207768\tScore: -27.97\n",
    "Learning Time: 47.9095478057861319\tScore: -18.41\n",
    "Learning Time: 41.6986820697784404\tScore: -28.15\n",
    "Learning Time: 49.3256709575653180\tScore: -18.83\n",
    "Learning Time: 42.3512620925903395\tScore: -25.61\n",
    "Learning Time: 41.9399950504303.14\tScore: -44.35\n",
    "Learning Time: 42.0089368820190424\tScore: -31.94\n",
    "Learning Time: 41.7282967567443850\tScore: -30.816\n",
    "Episode 1300\tAverage Score: -26.92\tScore: -24.74\n",
    "Learning Time: 42.9301068782806490\tScore: -25.28\n",
    "Learning Time: 42.1512911319732757\tScore: -18.79\n",
    "Learning Time: 42.9341220855712908\tScore: -11.85\n",
    "Learning Time: 42.3626670837402343\tScore: -13.46\n",
    "Learning Time: 43.1760270595550545\tScore: -14.05\n",
    "Learning Time: 39.0333838462829650\tScore: -23.025\n",
    "Learning Time: 39.2813110351562569\tScore: -23.63\n",
    "Learning Time: 40.1567578315734861\tScore: -25.58\n",
    "Learning Time: 43.0799899101257304\tScore: -113.61\n",
    "Learning Time: 47.1953339576721210\tScore: -42.52\n",
    "Learning Time: 43.6321978569030766\tScore: -30.29\n",
    "Learning Time: 43.7692868709564291\tScore: -16.636\n",
    "Learning Time: 50.6364340782165599\tScore: -105.12\n",
    "Learning Time: 47.9819059371948241\tScore: -108.53\n",
    "Episode 1400\tAverage Score: -38.10\tScore: -108.70\n",
    "Learning Time: 45.7070763111114508\tScore: -18.28\n",
    "Learning Time: 47.9037268161773704\tScore: -15.655\n",
    "Learning Time: 47.9066970348358153\tScore: -15.75\n",
    "Learning Time: 43.8121950626373354\tScore: -24.359\n",
    "Learning Time: 46.6754729747772230\tScore: -12.442\n",
    "Learning Time: 48.5181260108947751\tScore: -21.611\n",
    "Learning Time: 45.6160356998443606\tScore: -111.23\n",
    "Learning Time: 46.6777288913726827\tScore: -121.98\n",
    "Learning Time: 42.7118852138519319\tScore: -116.59\n",
    "Learning Time: 46.6691117286682165\tScore: -28.622\n",
    "Learning Time: 45.9012007713317923\tScore: -36.36\n",
    "Learning Time: 47.1364438533782961\tScore: -30.17\n",
    "Learning Time: 47.7135169506073.48\tScore: -24.95\n",
    "Learning Time: 50.4145550727844248\tScore: -17.46\n",
    "Learning Time: 47.3316240310668956\tScore: -30.86\n",
    "Episode 1500\tAverage Score: -37.64\tScore: -18.61\n",
    "Learning Time: 48.9877791404724162\tScore: -16.32\n",
    "Learning Time: 51.1212730407714845\tScore: -29.79\n",
    "Learning Time: 44.1742072105407785\tScore: -22.40\n",
    "Learning Time: 42.8843109607696506\tScore: -19.83\n",
    "Learning Time: 42.4952540397644040\tScore: -21.16\n",
    "Learning Time: 44.3001699447631846\tScore: -20.202\n",
    "Learning Time: 44.1330888271331879\tScore: -25.75\n",
    "Learning Time: 44.8928189277648926\tScore: -30.13\n",
    "Learning Time: 46.4897408485412676\tScore: -28.37\n",
    "Learning Time: 55.8327958583831826\tScore: -109.42\n",
    "Learning Time: 46.6438789367675867\tScore: -33.81\n",
    "Learning Time: 46.9498980045318645\tScore: -113.82\n",
    "Learning Time: 51.0569839477539066\tScore: -28.11\n",
    "Learning Time: 42.1068120002746637\tScore: -38.530\n",
    "Learning Time: 44.2449059486389160\tScore: -125.17\n",
    "Episode 1600\tAverage Score: -40.73\tScore: -23.792\n",
    "Learning Time: 46.5267801284790048\tScore: -103.94\n",
    "Learning Time: 46.0171959400177.01\tScore: -14.02\n",
    "Learning Time: 46.5032598972320567\tScore: -30.075\n",
    "Learning Time: 46.0360748767852804\tScore: -33.885\n",
    "Learning Time: 45.3479828834533731\tScore: -22.92\n",
    "Learning Time: 42.8594799041748058\tScore: -30.40\n",
    "Learning Time: 44.9049100875854580\tScore: -23.28\n",
    "Learning Time: 50.5000438690185554\tScore: -40.65\n",
    "Learning Time: 50.0993680953979503\tScore: -27.12\n",
    "Learning Time: 48.6950767040252787\tScore: -24.37\n",
    "Learning Time: 46.4828779697418267\tScore: -31.60\n",
    "Learning Time: 51.4060847759246884\tScore: -25.74\n",
    "Learning Time: 55.5760419368743960\tScore: -10.560\n",
    "Learning Time: 42.8585369586944689\tScore: -26.373\n",
    "Learning Time: 42.4714128971099855\tScore: -39.32\n",
    "Learning Time: 42.3689308166503936\tScore: -24.106\n",
    "Episode 1700\tAverage Score: -36.37\tScore: -13.89\n",
    "Learning Time: 46.1764481067657528\tScore: -17.33\n",
    "Learning Time: 46.0451016426086484\tScore: -15.049\n",
    "Learning Time: 46.5364708900451661\tScore: -17.685\n",
    "Learning Time: 46.2100329399108904\tScore: -17.90\n",
    "Learning Time: 42.5851671695709208\tScore: -105.59\n",
    "Learning Time: 45.3486309051513750\tScore: -12.64\n",
    "Learning Time: 48.3145380020141681\tScore: -16.790\n",
    "Learning Time: 43.3543767929077150\tScore: -23.17\n",
    "Learning Time: 51.0337831974029545\tScore: -24.25\n",
    "Learning Time: 44.0231702327728337\tScore: -11.26\n",
    "Learning Time: 49.8830740451812741\tScore: -105.96\n",
    "Learning Time: 44.0449199676513745\tScore: -24.35\n",
    "Learning Time: 46.9313490390777644\tScore: -110.25\n",
    "Learning Time: 46.9195659160614.32\tScore: -20.162\n",
    "Learning Time: 45.7335951328277618\tScore: -24.059\n",
    "Episode 1800\tAverage Score: -38.20\tScore: -119.77\n",
    "Learning Time: 45.1481337547302254\tScore: -110.49\n",
    "Learning Time: 44.2870111465454140\tScore: -24.869\n",
    "Learning Time: 46.7266621589660645\tScore: -17.593\n",
    "Learning Time: 45.1171488761901867\tScore: -24.778\n",
    "Learning Time: 42.3740322589874312\tScore: -20.05\n",
    "Learning Time: 40.1253099441528398\tScore: -24.892\n",
    "Learning Time: 39.8999710083007884\tScore: -103.34\n",
    "Learning Time: 39.5641746520996166\tScore: -27.726\n",
    "Learning Time: 44.6625883579254153\tScore: -30.299\n",
    "Learning Time: 40.6032531261444133\tScore: -27.692\n",
    "Learning Time: 39.2227330207824761\tScore: -29.22\n",
    "Episode 1900\tAverage Score: -59.90\tScore: -111.90\n",
    "Learning Time: 39.2748320102691658\tScore: -35.452\n",
    "Learning Time: 38.8785018920898449\tScore: -23.337\n",
    "Learning Time: 38.7682087421417240\tScore: -31.315\n",
    "Learning Time: 39.2044599056243951\tScore: -103.58\n",
    "Learning Time: 39.0119411945343.74\tScore: -103.85\n",
    "Learning Time: 38.9267399311065745\tScore: -36.870\n",
    "Learning Time: 37.5925519466400157\tScore: -33.664\n",
    "Learning Time: 37.7142670154571523\tScore: -30.215\n",
    "Learning Time: 37.9283688068389928\tScore: -31.495\n",
    "Learning Time: 37.9681451320648256\tScore: -21.54\n",
    "Learning Time: 37.7515597343444869\tScore: -22.71\n",
    "Learning Time: 38.2299361228942942\tScore: -104.41\n",
    "Learning Time: 53.2224099636077953\tScore: -109.46\n",
    "Learning Time: 1782.70367169380194\tScore: -21.94\n",
    "Episode 2000\tAverage Score: -48.73\tScore: -28.547\n",
    "Learning Time: 40.1072757244110108\tScore: -115.36\n",
    "Learning Time: 39.8173630237579354\tScore: -28.811\n",
    "Learning Time: 39.0033209323883069\tScore: -29.15\n",
    "Learning Time: 38.7237589359283459\tScore: -35.722\n",
    "Learning Time: 40.9716911315918.72\tScore: -33.50\n",
    "Learning Time: 38.9425621032714840\tScore: -36.300\n",
    "Learning Time: 38.5508911609649661\tScore: -38.866\n",
    "Learning Time: 38.7329928874969529\tScore: -108.92\n",
    "Learning Time: 38.4791398048400951\tScore: -32.397\n",
    "Learning Time: 38.9325821399688756\tScore: -110.71\n",
    "Learning Time: 38.3454651832580639\tScore: -54.637\n",
    "Learning Time: 38.3532819747924805\tScore: -59.573\n",
    "Episode 2100\tAverage Score: -65.38\tScore: -49.498\n",
    "Learning Time: 38.4015991687774663\tScore: -47.63\n",
    "Learning Time: 37.0621423721313536\tScore: -55.291\n",
    "Learning Time: 37.3237171173095754\tScore: -66.309\n",
    "Learning Time: 36.9170858860015967\tScore: -61.239\n",
    "Learning Time: 37.0461139678955159\tScore: -72.121\n",
    "Learning Time: 37.6828618049621667\tScore: -60.106\n",
    "Learning Time: 38.8642320632934682\tScore: -67.406\n",
    "Learning Time: 37.3779289722442639\tScore: -66.653\n",
    "Learning Time: 37.2195560932159484\tScore: -62.954\n",
    "Learning Time: 36.7853131294250589\tScore: -53.538\n",
    "Learning Time: 37.0135233402252219\tScore: -109.16\n",
    "Episode 2200\tAverage Score: -82.47\tScore: -45.004\n",
    "Learning Time: 37.131163120269775\n",
    "Learning Time: 38.5603919029235847\tScore: -121.66\n",
    "Learning Time: 38.0560498237609866\tScore: -62.626\n",
    "Learning Time: 39.2211518287658778\tScore: -50.847\n",
    "Learning Time: 39.4723792076110848\tScore: -109.20\n",
    "Learning Time: 38.3620851039886531\tScore: -109.77\n",
    "Learning Time: 38.2402420043945392\tScore: -106.02\n",
    "Learning Time: 38.2057130336761557\tScore: -129.22\n",
    "Learning Time: 38.1684286594390962\tScore: -54.908\n",
    "Episode 2300\tAverage Score: -90.15\tScore: -56.921\n",
    "Learning Time: 38.32826018333435\n",
    "Learning Time: 37.9962320327758855\tScore: -50.290\n",
    "Learning Time: 38.1408498287200930\tScore: -45.573\n",
    "Learning Time: 37.9218039512634350\tScore: -55.913\n",
    "Learning Time: 38.8516297340393116\tScore: -46.63\n",
    "Learning Time: 38.4694867134094243\tScore: -134.72\n",
    "Learning Time: 38.0232138633728.26\tScore: -102.87\n",
    "Learning Time: 38.4803090095525.60\tScore: -110.81\n",
    "Learning Time: 38.0516288280487060\tScore: -27.235\n",
    "Learning Time: 37.8877630233764652\tScore: -40.397\n",
    "Learning Time: 37.8675010204315256\tScore: -47.857\n",
    "Learning Time: 38.1522800922393870\tScore: -103.62\n",
    "Episode 2400\tAverage Score: -74.44\tScore: -130.62\n",
    "Learning Time: 38.1433091163635254\tScore: -104.51\n",
    "Learning Time: 38.4205458164215127\tScore: -109.41\n",
    "Learning Time: 38.5601353645324717\tScore: -102.33\n",
    "Learning Time: 38.5608069896698.89\tScore: -55.043\n",
    "Learning Time: 38.2737209796905508\tScore: -38.90\n",
    "Learning Time: 38.8787438869476391\tScore: -42.629\n",
    "Learning Time: 38.4177069664001544\tScore: -31.080\n",
    "Learning Time: 39.5383489131927567\tScore: -29.319\n",
    "Learning Time: 38.8329219818115204\tScore: -109.38\n",
    "Learning Time: 39.6512629985809315\tScore: -38.142\n",
    "Learning Time: 39.6943120956420925\tScore: -28.777\n",
    "Learning Time: 38.4932961463928233\tScore: -44.205\n",
    "Episode 2500\tAverage Score: -71.13\tScore: -104.94\n",
    "Learning Time: 38.7969405651092511\tScore: -14.491\n",
    "Learning Time: 38.6863617897033721\tScore: -49.108\n",
    "Episode 2519\tAverage Score: -63.25\tScore: -114.65"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
