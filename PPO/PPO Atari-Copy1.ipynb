{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import gym\n",
    "from Config import Config\n",
    "# from util import train\n",
    "from Models import ActorCritic\n",
    "from Networks import cnn_head_model, actor_model, critic_model, head_model\n",
    "from Memory import Memory\n",
    "from baselines.common.cmd_util import make_env\n",
    "from baselines.common.atari_wrappers import wrap_deepmind, make_atari\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecEnvWrapper\n",
    "import pdb\n",
    "\n",
    "from PPO import PPOPixel\n",
    "from Networks import cnn_head_model, actor_model, critic_model, head_model\n",
    "from Models import ActorCritic\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import copy\n",
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env_id = \"BreakoutNoFrameskip-v4\"\n",
    "env = make_atari(env_id)\n",
    "env = wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=True, scale=False)\n",
    "\n",
    "# config = Config(gym.make('CartPole-v1'))\n",
    "config = Config(env)\n",
    "\n",
    "config.update_every = 500\n",
    "config.num_learn = 4\n",
    "config.win_condition = 230\n",
    "config.n_episodes = 1000\n",
    "config.max_t = 700\n",
    "\n",
    "config.Memory = Memory\n",
    "config.Model = ActorCritic\n",
    "config.head_model = functools.partial(cnn_head_model, config)\n",
    "config.actor_model = functools.partial(actor_model, config)\n",
    "config.critic_model = functools.partial(critic_model, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Image shape to channels x weight x height\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.transpose(observation, axes=(2, 0, 1))\n",
    "\n",
    "def wrap_pytorch(env):\n",
    "    return ImageToPyTorch(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(gym_id, seed, idx):\n",
    "    def thunk():\n",
    "        env = gym.make(gym_id)\n",
    "       \n",
    "        env = wrap_pytorch(\n",
    "            wrap_deepmind(\n",
    "                env,\n",
    "                clip_rewards=True,\n",
    "                frame_stack=True,\n",
    "                scale=False,\n",
    "            )\n",
    "        )\n",
    "        env.seed(seed)\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        return env\n",
    "    return thunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(env_id, 123343534, 1)\n",
    "env = env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â PPO test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PPO import PPOPixel\n",
    "from Networks import cnn_head_model, actor_model, critic_model, head_model\n",
    "from Models import ActorCritic\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import copy\n",
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# env = copy.deepcopy(config.env)\n",
    "steps = 0\n",
    "scores_deque = deque(maxlen=100)\n",
    "scores = []\n",
    "average_scores = []\n",
    "max_score = -np.Inf\n",
    "\n",
    "agent = PPOPixel(config)\n",
    "\n",
    "state = env.reset()\n",
    "score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# obs = torch.zeros((num_steps, 1) + env.observation_space.shape)\n",
    "# actions = torch.zeros((num_steps,1 ) + env.action_space.shape)\n",
    "# logprobs = torch.zeros((num_steps,1))\n",
    "# rewards = torch.zeros((num_steps,1))\n",
    "# dones = torch.zeros((num_steps,1))\n",
    "# values = torch.zeros((num_steps,1))\n",
    "\n",
    "# obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 84, 84])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(env.reset()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Models import ActorCritic\n",
    "\n",
    "# score = 0\n",
    "\n",
    "# num_steps = 3\n",
    "\n",
    "# obs = torch.zeros((num_steps, 1, 4, 84, 84))\n",
    "# actions = torch.zeros(num_steps, 1)\n",
    "# logsprobs = torch.zeros(num_steps, 1)\n",
    "# rewards = torch.zeros(num_steps)\n",
    "# dones = torch.zeros(num_steps)\n",
    "# values = torch.zeros(num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 4, 84, 84])\n",
      "torch.Size([4, 84, 84])\n",
      "tensor([0])\n",
      "torch.Size([4, 84, 84])\n",
      "tensor([0])\n",
      "torch.Size([4, 84, 84])\n",
      "tensor([2])\n",
      "torch.Size([4, 84, 84])\n",
      "tensor([3])\n",
      "torch.Size([4, 84, 84])\n",
      "tensor([1])\n",
      "torch.Size([4, 84, 84])\n",
      "tensor([0])\n",
      "torch.Size([4, 84, 84])\n",
      "tensor([3])\n",
      "torch.Size([4, 84, 84])\n",
      "tensor([0])\n",
      "torch.Size([4, 84, 84])\n",
      "tensor([3])\n",
      "torch.Size([4, 84, 84])\n",
      "tensor([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3305],\n",
       "        [-1.3331],\n",
       "        [-1.4234],\n",
       "        [-1.3371],\n",
       "        [-1.4619],\n",
       "        [-1.3260],\n",
       "        [-1.3330],\n",
       "        [-1.3320],\n",
       "        [-1.3344],\n",
       "        [-1.3388]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Models import ActorCritic\n",
    "\n",
    "model = ActorCritic(config)\n",
    "\n",
    "num_steps = 10\n",
    "\n",
    "obs = torch.zeros((num_steps, 1) + env.observation_space.shape)\n",
    "print(obs.shape)\n",
    "actions = torch.zeros(num_steps, 1)\n",
    "logsprobs = torch.zeros(num_steps, 1)\n",
    "rewards = torch.zeros(num_steps)\n",
    "dones = torch.zeros(num_steps)\n",
    "values = torch.zeros(num_steps)\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "for t in range(num_steps):\n",
    "    steps += 1\n",
    "\n",
    "    # Shape obs\n",
    "    print(torch.FloatTensor(state).shape)\n",
    "    obs[t] = torch.FloatTensor(state)\n",
    "    \n",
    "    # Get action & save\n",
    "    with torch.no_grad():\n",
    "        action, log_prob, value, entr = model.act(obs[t])\n",
    "        print(action)\n",
    "    actions[t] = action\n",
    "    logsprobs[t] = log_prob\n",
    "    values[t] = value\n",
    "    \n",
    "    # Act logic & save\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    rewards[t] = reward\n",
    "    dones[t] = done\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    # Update \n",
    "    score += reward\n",
    "logsprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape obs: torch.Size([10, 1, 4, 84, 84])\n",
      "Shape action: torch.Size([10, 1])\n",
      "Shape log probs: torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape obs: {}\".format(obs.shape))\n",
    "print(\"Shape action: {}\".format(actions.shape))\n",
    "print(\"Shape log probs: {}\".format(logsprobs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped state space: torch.Size([10, 4, 84, 84])\n",
      "reshaped state space: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "b_obs = obs.reshape((-1,)+env.observation_space.shape)\n",
    "# b_prev_state = obs.squeeze(dim=1)\n",
    "b_actions = actions.reshape((-1,)+env.action_space.shape)\n",
    "\n",
    "print(\"reshaped state space: {}\".format(b_obs.shape))\n",
    "print(\"reshaped state space: {}\".format(b_actions.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3294, -1.3326, -1.4244, -1.3367, -1.4625, -1.3259, -1.3330, -1.3329,\n",
      "        -1.3347, -1.3395])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    a, lp, v, e = model.act(b_obs, b_actions)\n",
    "    print(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3305], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3331], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.4234], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3371], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.4619], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3260], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3330], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3320], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3344], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3388], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_steps):\n",
    "    a, lp, v, e = model.act(obs[i], actions[i])\n",
    "    print(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3305], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3331], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.4234], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3371], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.4619], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3260], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3330], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3320], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3344], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3388], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "ba = None\n",
    "for i in range(num_steps):\n",
    "    ba = torch.empty(1)\n",
    "    ba[0] = b_actions[i]\n",
    "    a, lp, v, e = model.act(b_obs[i].unsqueeze(dim=0), ba)\n",
    "    print(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 84, 84])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(b_obs[i].unsqueeze(dim=0).shape)\n",
    "print(ba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_obs[[1,2]].shape\n",
    "b_actions[[1,2]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3334, -1.4240], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# ba = torch.empty(2)\n",
    "# ba[0] = b_actions[[1,2]]\n",
    "a, lp, v, e = model.act(b_obs[[1,2]], b_actions[[1,2]])\n",
    "print(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3294, -1.3326, -1.4244, -1.3367, -1.4625, -1.3259, -1.3330, -1.3329,\n",
       "        -1.3347, -1.3395], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, lp, v, e = model.act(b_obs, b_actions)\n",
    "lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even more broken down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Costa agent\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, envs, frames=4):\n",
    "        super(Agent, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            Scale(1/255),\n",
    "            layer_init(nn.Conv2d(frames, 32, 8, stride=4)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(32, 64, 4, stride=2)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(64, 64, 3, stride=1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            layer_init(nn.Linear(3136, 512)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.actor = layer_init(nn.Linear(512, envs.action_space.n), std=0.01)\n",
    "        self.critic = layer_init(nn.Linear(512, 1), std=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "    def get_action(self, x, action=None):\n",
    "        logits = self.actor(self.forward(x))\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy()\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.critic(self.forward(x))\n",
    "class Scale(nn.Module):\n",
    "    def __init__(self, scale):\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.scale\n",
    "\n",
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original\n",
    "class ActorCritic(nn.Module):\n",
    "  \"\"\"Some Information about ActorCritic\"\"\"\n",
    "  def __init__(self, config):\n",
    "    super(ActorCritic, self).__init__()\n",
    "\n",
    "    self.head = config.head_model()\n",
    "\n",
    "    self.actor = config.actor_model()\n",
    "    self.actor.add_module(\n",
    "      \"actor_linear\",\n",
    "      nn.Linear(config.hidden_size, config.action_space)\n",
    "    )\n",
    "\n",
    "    self.critic = config.critic_model()\n",
    "    self.critic.add_module(\n",
    "      \"critic_linear\",\n",
    "      nn.Linear(config.hidden_size, 1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.head(x)\n",
    "    value = self.critic(x)\n",
    "    action = self.actor(x)\n",
    "    return action, value\n",
    "  \n",
    "  def act(self, x, action=None):\n",
    "    logits, value = self.forward(x)\n",
    "    probs = Categorical(logits=logits)\n",
    "    if action is None:\n",
    "      action = probs.sample()\n",
    "    return action, probs.log_prob(action), value, probs.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import ActorCritic\n",
    "\n",
    "\n",
    "model = ActorCritic(config)\n",
    "# Costa\n",
    "model = Agent(env)\n",
    "\n",
    "num_steps = 10\n",
    "\n",
    "obs = torch.zeros((num_steps, 1) + env.observation_space.shape)\n",
    "actions = torch.zeros(num_steps, 1)\n",
    "logsprobs = torch.zeros(num_steps, 1)\n",
    "rewards = torch.zeros(num_steps)\n",
    "dones = torch.zeros(num_steps)\n",
    "values = torch.zeros(num_steps)\n",
    "\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[ 0.0037, -0.0013, -0.0034,  0.0003]])\n",
      "Logits: tensor([[ 0.0037, -0.0013, -0.0034,  0.0004]])\n",
      "Logits: tensor([[ 0.0037, -0.0013, -0.0034,  0.0003]])\n",
      "Logits: tensor([[ 0.0037, -0.0013, -0.0034,  0.0003]])\n",
      "Logits: tensor([[ 0.0037, -0.0013, -0.0034,  0.0003]])\n",
      "Logits: tensor([[ 0.0037, -0.0013, -0.0034,  0.0003]])\n",
      "Logits: tensor([[ 0.0037, -0.0013, -0.0034,  0.0003]])\n",
      "Logits: tensor([[ 0.0037, -0.0013, -0.0034,  0.0003]])\n",
      "Logits: tensor([[ 0.0037, -0.0013, -0.0034,  0.0003]])\n",
      "Logits: tensor([[ 0.0037, -0.0013, -0.0034,  0.0003]])\n",
      "tensor([[-1.3824],\n",
      "        [-1.3875],\n",
      "        [-1.3824],\n",
      "        [-1.3824],\n",
      "        [-1.3858],\n",
      "        [-1.3895],\n",
      "        [-1.3824],\n",
      "        [-1.3824],\n",
      "        [-1.3895],\n",
      "        [-1.3875]])\n",
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for t in range(num_steps):\n",
    "    steps += 1\n",
    "\n",
    "    # Shape obs\n",
    "    obs[t] = torch.FloatTensor(state)\n",
    "    \n",
    "    # Get action & save\n",
    "    with torch.no_grad():\n",
    "        # Original\n",
    "#         logits, value = model(obs[t])\n",
    "        # costa\n",
    "        logits = model.actor(model(obs[t]))\n",
    "        print(\"Logits: {}\".format(logits))\n",
    "        probs = Categorical(logits=logits)\n",
    "        action = probs.sample()\n",
    "\n",
    "    actions[t] = action\n",
    "    logsprobs[t] = probs.log_prob(action)\n",
    "    values[t] = value\n",
    "    \n",
    "    # Act logic & save\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    rewards[t] = reward\n",
    "    dones[t] = done\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    # Update \n",
    "    score += reward\n",
    "\n",
    "print(logsprobs)\n",
    "print(logsprobs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped state space: torch.Size([10, 4, 84, 84])\n",
      "reshaped state space: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "b_obs = obs.reshape((-1,)+env.observation_space.shape)\n",
    "# b_prev_state = obs.squeeze(dim=1)\n",
    "b_actions = actions.reshape((-1,)+env.action_space.shape)\n",
    "\n",
    "print(\"reshaped state space: {}\".format(b_obs.shape))\n",
    "print(\"reshaped state space: {}\".format(b_actions.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0037, -0.0013, -0.0034,  0.0003],\n",
       "        [ 0.0037, -0.0013, -0.0034,  0.0004],\n",
       "        [ 0.0037, -0.0013, -0.0034,  0.0003],\n",
       "        [ 0.0037, -0.0013, -0.0034,  0.0003],\n",
       "        [ 0.0037, -0.0013, -0.0034,  0.0003],\n",
       "        [ 0.0037, -0.0013, -0.0034,  0.0003],\n",
       "        [ 0.0037, -0.0013, -0.0034,  0.0003],\n",
       "        [ 0.0037, -0.0013, -0.0034,  0.0003],\n",
       "        [ 0.0037, -0.0013, -0.0034,  0.0003],\n",
       "        [ 0.0037, -0.0013, -0.0034,  0.0003]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model.actor(model(b_obs))\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train-procgen",
   "language": "python",
   "name": "train-procgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
